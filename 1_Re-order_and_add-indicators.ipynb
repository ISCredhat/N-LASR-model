{
 "cells": [
  {
   "cell_type": "code",
   "id": "84f2fc06-dd16-4716-b352-7615a576a343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T14:12:39.798797Z",
     "start_time": "2024-11-04T14:12:39.404324Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from datetime import timedelta\n",
    "\n",
    "# all the names of my downloaded tickers\n",
    "tickers = [\"AAPL\", \"ADBE\", \"AIG\", \"ALL\", \"AMD\", \"AMAT\", \"AMGN\", \"AMZN\", \"AON\",\n",
    "    \"APD\", \"AVGO\", \"AXP\", \"BAC\", \"BABA\", \"BAX\", \"BBY\", \"BDX\", \"BIIB\", \"BLK\",\n",
    "    \"BMY\", \"BK\", \"CB\", \"C\", \"CHD\", \"CI\", \"CINF\", \"CL\", \"CLX\", \"CMG\",\n",
    "    \"CRM\", \"COST\", \"CRWD\", \"CSCO\", \"CVS\", \"DDOG\", \"DG\", \"DHR\", \"DOCU\", \"DPZ\",\n",
    "    \"DRI\", \"EW\", \"ECL\", \"F\", \"FDX\", \"FMC\", \"GM\", \"GILD\", \"GIS\", \"GOOG\",\n",
    "    \"GS\", \"HD\", \"HOG\", \"HUBS\", \"IBM\", \"IFF\", \"ILMN\", \"INTC\", \"INTU\", \"ISRG\",\n",
    "    \"JNJ\", \"JPM\", \"K\", \"KHC\", \"KR\", \"LNC\", \"LOW\", \"LULU\", \"MA\", \"MDB\",\n",
    "    \"MCD\", \"MDT\", \"META\", \"MKC\", \"MMM\", \"MSFT\", \"MU\", \"NET\", \"NFLX\", \"NOW\",\n",
    "    \"NVDA\", \"OKTA\", \"ORCL\", \"PEP\", \"PG\", \"PGR\", \"PFE\", \"PLTR\", \"PNC\", \"PPG\",\n",
    "    \"PRU\", \"PYPL\", \"REGN\", \"ROKU\", \"RNG\", \"RL\", \"SBUX\", \"SCHW\", \"SHOP\", \"SKX\",\n",
    "    \"SNOW\", \"SPGI\", \"SPY\", \"SQ\", \"SYK\", \"T\", \"TEAM\", \"TMO\", \"TRV\", \"TSCO\",\n",
    "    \"TSLA\", \"TXN\", \"TROW\", \"TWLO\", \"UA\", \"UAA\", \"UNH\", \"USB\", \"V\", \"VRTX\",\n",
    "    \"WBA\", \"WDAY\", \"WFC\", \"WMT\", \"YUM\", \"ZBH\", \"ZM\"]\n",
    "\n",
    "# just to make sure that data is ordered correctly\n",
    "def order_data(df):\n",
    "    df = df.sort_values(by='date')\n",
    "    return df\n",
    "\n",
    "# from github, just removes deprecated warnings etc.\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# massive function to calculate all technical indicators\n",
    "def add_indicators(matrix, k):\n",
    "    \n",
    "    rolling_window = 14\n",
    "    \n",
    "    open_col = pd.Series(matrix[k, :, 0])\n",
    "    high_col = pd.Series(matrix[k, :, 1])\n",
    "    low_col = pd.Series(matrix[k, :, 2])\n",
    "    close_col = pd.Series(matrix[k, :, 3])\n",
    "    volume_col = pd.Series(matrix[k, :, 4])\n",
    "\n",
    "    # Calculate indicators for the matrix\n",
    "    fisher = ta.fisher(high_col, low_col).iloc[:, 0].astype('float64')\n",
    "    dpo = ta.dpo(close_col)\n",
    "    corr = close_col.rolling(window=14).corr(close_col.shift(1))\n",
    "    adx = ta.adx(high_col, low_col, close_col)\n",
    "    rsi = ta.rsi(close_col)\n",
    "    uo = ta.uo(high_col, low_col, close_col)\n",
    "    willr = ta.willr(high_col, low_col, close_col)\n",
    "    kc_upper = ta.kc(high_col, low_col, close_col)\n",
    "    kama = ta.kama(close_col)\n",
    "    vtx = ta.vortex(high_col, low_col, close_col)\n",
    "    cmf = ta.cmf(high_col, low_col, close_col, volume_col)\n",
    "    kst = ta.kst(close_col)\n",
    "    eom = ta.eom(high_col, low_col, close_col, volume_col)\n",
    "    bop = ta.bop(open_col, high_col, low_col, close_col)\n",
    "    cci = ta.cci(high_col, low_col, close_col)\n",
    "    cmo = ta.cmo(close_col)\n",
    "    efi = (ta.efi(close_col, volume_col) - open_col) / open_col\n",
    "    eri = (ta.eri(high_col, low_col, close_col) - open_col) / open_col\n",
    "    ema = (ta.ema(close_col) - open_col) / open_col\n",
    "    hma = (ta.hma(close_col) - open_col) / open_col\n",
    "    linreg = (ta.linreg(close_col) - open_col) / open_col\n",
    "    slope = (ta.slope(close_col) - open_col) / open_col\n",
    "    median = (ta.median(close_col) - open_col) / open_col\n",
    "    macd = (ta.macd(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    mom = (ta.mom(close_col) - open_col) / open_col\n",
    "    obv = (ta.obv(close_col, volume_col) - open_col) / open_col\n",
    "    pvo = (ta.pvo(volume_col).iloc[:, 0] - open_col) / open_col\n",
    "    roc = (ta.roc(close_col) - open_col) / open_col\n",
    "    pvt = (ta.pvt(close_col, volume_col) - open_col) / open_col\n",
    "    sma = (ta.sma(close_col) - open_col) / open_col\n",
    "    stddev = (ta.stdev(close_col) - open_col) / open_col\n",
    "    supertrend = (ta.supertrend(high_col, low_col, close_col).iloc[:, 0] - open_col) / open_col\n",
    "    t3 = (ta.t3(close_col) - open_col) / open_col\n",
    "    trima = (ta.trima(close_col) - open_col) / open_col\n",
    "    true_range = (ta.true_range(high_col, low_col, close_col) - open_col) / open_col\n",
    "    wma = (ta.wma(close_col) - open_col) / open_col\n",
    "    tema = (ta.tema(close_col) - open_col) / open_col\n",
    "    nvi = (ta.nvi(close_col, volume_col) - open_col) / open_col\n",
    "    nvi = nvi.infer_objects()\n",
    "    pvi = (ta.pvi(close_col, volume_col) - open_col) / open_col\n",
    "    pvi = pvi.infer_objects()\n",
    "    chop = (ta.chop(high_col, low_col, close_col) - open_col) / open_col\n",
    "    atr = (ta.atr(high_col, low_col, close_col) - open_col) / open_col\n",
    "    ao = (ta.ao(high_col, low_col) - open_col) / open_col\n",
    "    dm = (ta.dm(high_col, low_col).iloc[:, 0] - open_col) / open_col\n",
    "    dema = (ta.dema(close_col) - open_col) / open_col\n",
    "    bias = (ta.bias(close_col) - open_col) / open_col\n",
    "    cfo = (ta.cfo(close_col) - open_col) / open_col\n",
    "    cti = (ta.cti(close_col) - open_col) / open_col\n",
    "    inertia = (ta.inertia(close_col) - open_col) / open_col\n",
    "    inertia = inertia.infer_objects()\n",
    "    ppo = (ta.ppo(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    trix = (ta.trix(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    alma = (ta.alma(close_col) - open_col) / open_col\n",
    "    fwma = (ta.fwma(close_col) - open_col) / open_col\n",
    "    hilo = (ta.hilo(high_col, low_col, close_col).iloc[:, 0] - open_col) / open_col\n",
    "    hl2 = (ta.hl2(high_col, low_col) - open_col) / open_col\n",
    "    hwma = (ta.hwma(close_col) - open_col) / open_col\n",
    "    midpoint = (ta.midpoint(close_col) - open_col) / open_col\n",
    "    midprice = (ta.midprice(high_col, low_col) - open_col) / open_col\n",
    "    pwma = (ta.pwma(close_col) - open_col) / open_col\n",
    "    sinwma = (ta.sinwma(close_col) - open_col) / open_col\n",
    "    percent_return = ta.percent_return(close_col)\n",
    "    percent_return = percent_return.infer_objects()  # Add this only if it triggers the same warning   # Percent return doesn't need rolling mean\n",
    "    kurtosis = (ta.kurtosis(close_col) - open_col) / open_col\n",
    "    mad = (ta.mad(close_col) - open_col) / open_col\n",
    "    skew = (ta.skew(close_col) - open_col) / open_col\n",
    "    variance = (ta.variance(close_col) - open_col) / open_col\n",
    "\n",
    "    new_columns = [\n",
    "        fisher - fisher.rolling(rolling_window).mean(),\n",
    "        dpo - dpo.rolling(rolling_window).mean(),\n",
    "        corr - corr.rolling(rolling_window).mean(),\n",
    "        adx['ADX_14'] - adx['ADX_14'].rolling(rolling_window).mean(),\n",
    "        rsi - rsi.rolling(rolling_window).mean(),\n",
    "        uo - uo.rolling(rolling_window).mean(),\n",
    "        willr - willr.rolling(rolling_window).mean(),\n",
    "        kc_upper - kc_upper.rolling(rolling_window).mean(),\n",
    "        kama - kama.rolling(rolling_window).mean(),\n",
    "        vtx - vtx.rolling(rolling_window).mean(),\n",
    "        cmf - cmf.rolling(rolling_window).mean(),\n",
    "        kst - kst.rolling(rolling_window).mean(),\n",
    "        eom - eom.rolling(rolling_window).mean(),\n",
    "        bop - bop.rolling(rolling_window).mean(),\n",
    "        cci - cci.rolling(rolling_window).mean(),\n",
    "        cmo - cmo.rolling(rolling_window).mean(),\n",
    "        efi - efi.rolling(rolling_window).mean(),\n",
    "        ema - ema.rolling(rolling_window).mean(),\n",
    "        hma - hma.rolling(rolling_window).mean(),\n",
    "        linreg - linreg.rolling(rolling_window).mean(),\n",
    "        slope - slope.rolling(rolling_window).mean(),\n",
    "        median - median.rolling(rolling_window).mean(),\n",
    "        macd - macd.rolling(rolling_window).mean(),\n",
    "        mom - mom.rolling(rolling_window).mean(),\n",
    "        obv - obv.rolling(rolling_window).mean(),\n",
    "        pvo - pvo.rolling(rolling_window).mean(),\n",
    "        roc - roc.rolling(rolling_window).mean(),\n",
    "        pvt - pvt.rolling(rolling_window).mean(),\n",
    "        sma - sma.rolling(rolling_window).mean(),\n",
    "        stddev - stddev.rolling(rolling_window).mean(),\n",
    "        supertrend - supertrend.rolling(rolling_window).mean(),\n",
    "        t3 - t3.rolling(rolling_window).mean(),\n",
    "        trima - trima.rolling(rolling_window).mean(),\n",
    "        true_range - true_range.rolling(rolling_window).mean(),\n",
    "        wma - wma.rolling(rolling_window).mean(),\n",
    "        kurtosis - kurtosis.rolling(rolling_window).mean(),\n",
    "        mad - mad.rolling(rolling_window).mean(),\n",
    "        skew - skew.rolling(rolling_window).mean(),\n",
    "        variance - variance.rolling(rolling_window).mean(),\n",
    "        tema - tema.rolling(rolling_window).mean(),\n",
    "        nvi - nvi.rolling(rolling_window).mean(),\n",
    "        pvi - pvi.rolling(rolling_window).mean(),\n",
    "        chop - chop.rolling(rolling_window).mean(),\n",
    "        atr - atr.rolling(rolling_window).mean(),\n",
    "        ao - ao.rolling(rolling_window).mean(),\n",
    "        dm - dm.rolling(rolling_window).mean(),\n",
    "        dema - dema.rolling(rolling_window).mean(),\n",
    "        bias - bias.rolling(rolling_window).mean(),\n",
    "        cfo - cfo.rolling(rolling_window).mean(),\n",
    "        cti - cti.rolling(rolling_window).mean(),\n",
    "        inertia - inertia.rolling(rolling_window).mean(),\n",
    "        ppo - ppo.rolling(rolling_window).mean(),\n",
    "        trix - trix.rolling(rolling_window).mean(),\n",
    "        alma - alma.rolling(rolling_window).mean(),\n",
    "        fwma - fwma.rolling(rolling_window).mean(),\n",
    "        hilo - hilo.rolling(rolling_window).mean(),\n",
    "        hl2 - hl2.rolling(rolling_window).mean(),\n",
    "        hwma - hwma.rolling(rolling_window).mean(),\n",
    "        midpoint - midpoint.rolling(rolling_window).mean(),\n",
    "        midprice - midprice.rolling(rolling_window).mean(),\n",
    "        pwma - pwma.rolling(rolling_window).mean(),\n",
    "        sinwma - sinwma.rolling(rolling_window).mean(),\n",
    "        percent_return - percent_return.rolling(rolling_window).mean()  # No rolling mean needed\n",
    "    ]\n",
    "\n",
    "    # Stack the columns side by side and return\n",
    "    indicator_matrix = np.column_stack(new_columns)\n",
    "\n",
    "    return indicator_matrix\n",
    "\n",
    "print('Done')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7d8dc-fe1f-4a7e-b349-7b1e0216deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order imported data, make list of min timesteps within a stock import so that training data is initially compilable\n",
    "'''need to refine this section, may actually just be unnecessary'''\n",
    "#common_dates = None\n",
    "#for ticker in tickers:\n",
    "#    ticker_data = pd.read_csv(f'{ticker}_1hr_historical_data_final.csv')\n",
    "#    ticker_data['date'] = pd.to_datetime(ticker_data['date'], errors='coerce')\n",
    "#\n",
    "#    # Ensure the data is ordered\n",
    "#    ticker_data_ordered = order_data(ticker_data)\n",
    "#\n",
    "#    # Truncate data for testing purposes\n",
    "#    ticker_data_truncated = ticker_data_ordered[(ticker_data_ordered['date'] >= ticker_data_ordered['date'].max() - timedelta(weeks=70))].copy()\n",
    "#\n",
    "#    # Find common dates across tickers\n",
    "#    if common_dates is None:\n",
    "#        common_dates = set(ticker_data_truncated['date'])\n",
    "#    else:\n",
    "#        common_dates &= set(ticker_data_truncated['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344bb0e-9b4b-4f3a-b120-a712b708fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slightly innefficent, however import data again, truncate to needed time period,\n",
    "# add day and hour columns as 6th and 7th (index 5 and 6)\n",
    "\n",
    "ticker_arrays = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_data = pd.read_csv(f'{ticker}_1hr_historical_data_final.csv')\n",
    "    ticker_data['date'] = pd.to_datetime(ticker_data['date'], errors='coerce')\n",
    "\n",
    "    # Order the data\n",
    "    ticker_data_ordered = order_data(ticker_data)\n",
    "\n",
    "    # Truncate the data\n",
    "    ticker_data_truncated = ticker_data_ordered[(ticker_data_ordered['date'] >= ticker_data_ordered['date'].max() - timedelta(weeks=70))].copy()\n",
    "\n",
    "    # Filter by common dates\n",
    "    ticker_data_filtered = ticker_data_truncated[ticker_data_truncated['date'].isin(common_dates)]\n",
    "\n",
    "    # Convert to numpy array and append to ticker arrays\n",
    "    ticker_array_half = ticker_data_filtered.to_numpy()\n",
    "    \n",
    "    # Create empty dataframe for day and hour columns\n",
    "    ticker_data_filtered_date = pd.DataFrame()\n",
    "    ticker_data_filtered_date['Day'] = ticker_data_filtered['date'].dt.dayofweek\n",
    "    ticker_data_filtered_date['Hr'] = ticker_data_filtered['date'].dt.hour\n",
    "\n",
    "    ticker_array_datetime = ticker_data_filtered_date.to_numpy()\n",
    "\n",
    "    # Combine open, high, low, close, volume data with date and hour columns\n",
    "    total_ticker_array = np.concatenate((ticker_array_half[:, 1:-2], ticker_array_datetime), axis=1)\n",
    "\n",
    "    # Append to the list of ticker arrays\n",
    "    ticker_arrays.append(total_ticker_array)\n",
    "\n",
    "ticker_matrix = np.stack(ticker_arrays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7cf9954-c1c4-4772-a681-93133435bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_time_steps = ticker_arrays[0].shape[0]\n",
    "#\n",
    "#filtered_ticker_arrays = []\n",
    "#for idx, arr in enumerate(ticker_arrays):\n",
    "#    missing_values = min_time_steps - arr.shape[0]\n",
    "#    \n",
    "#    if missing_values > 50:\n",
    "#        print(f\"Array {idx} has more than 50 missing values: {missing_values} missing, skipping this stock.\")\n",
    "#    else:\n",
    "#        filtered_ticker_arrays.append(arr)\n",
    "#\n",
    "#filtered_ticker_arrays = [arr[:min_time_steps, :] for arr in filtered_ticker_arrays]\n",
    "#\n",
    "#filtered_ticker_matrix = np.stack(filtered_ticker_arrays, axis=0)\n",
    "\n",
    "\n",
    "'''also need to refine this, not sure if needed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed46835-e9f5-48f2-b37a-142a4e852bb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ticker_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m indicator_arrays \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(ticker_matrix\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m      4\u001B[0m     ind_per_stock \u001B[38;5;241m=\u001B[39m add_indicators(ticker_matrix, r)\n\u001B[0;32m      5\u001B[0m     indicator_arrays\u001B[38;5;241m.\u001B[39mappend(ind_per_stock)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ticker_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "#create indicator matrix\n",
    "\n",
    "indicator_arrays = []\n",
    "\n",
    "for r in range(ticker_matrix.shape[0]):\n",
    "    ind_per_stock = add_indicators(ticker_matrix, r)\n",
    "    indicator_arrays.append(ind_per_stock)\n",
    "    num_of_indicators = ind_per_stock.shape[0]\n",
    "\n",
    "#create new matrix for only indicators for each ticker\n",
    "indicator_matrix =  np.stack(indicator_arrays, axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
