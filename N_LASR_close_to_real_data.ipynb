{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6c3e1d10-9fa2-4d67-bfd0-ca68702925c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 2337, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# all the names of my downloaded tickers\n",
    "tickers = [\"AAPL\", \"ADBE\", \"AIG\", \"ALL\", \"AMD\", \"AMAT\", \"AMGN\", \"AMZN\", \"AON\",\n",
    "    \"APD\", \"AVGO\", \"AXP\", \"BAC\", \"BABA\", \"BAX\", \"BBY\", \"BDX\", \"BIIB\", \"BLK\",\n",
    "    \"BMY\", \"BK\", \"CB\", \"C\", \"CHD\", \"CI\", \"CINF\", \"CL\", \"CLX\", \"CMG\",\n",
    "    \"CRM\", \"COST\", \"CRWD\", \"CSCO\", \"CVS\", \"DDOG\", \"DG\", \"DHR\", \"DOCU\", \"DPZ\",\n",
    "    \"DRI\", \"EW\", \"ECL\", \"F\", \"FDX\", \"FMC\", \"GM\", \"GILD\", \"GIS\", \"GOOG\",\n",
    "    \"GS\", \"HD\", \"HOG\", \"HUBS\", \"IBM\", \"IFF\", \"ILMN\", \"INTC\", \"INTU\", \"ISRG\",\n",
    "    \"JNJ\", \"JPM\", \"K\", \"KHC\", \"KR\", \"LNC\", \"LOW\", \"LULU\", \"MA\", \"MDB\",\n",
    "    \"MCD\", \"MDT\", \"META\", \"MKC\", \"MMM\", \"MSFT\", \"MU\", \"NET\", \"NFLX\", \"NOW\",\n",
    "    \"NVDA\", \"OKTA\", \"ORCL\", \"PEP\", \"PG\", \"PGR\", \"PFE\", \"PLTR\", \"PNC\", \"PPG\",\n",
    "    \"PRU\", \"PYPL\", \"REGN\", \"ROKU\", \"RNG\", \"RL\", \"SBUX\", \"SCHW\", \"SHOP\", \"SKX\",\n",
    "    \"SNOW\", \"SPGI\", \"SPY\", \"SQ\", \"SYK\", \"T\", \"TEAM\", \"TMO\", \"TRV\", \"TSCO\",\n",
    "    \"TSLA\", \"TXN\", \"TROW\", \"TWLO\", \"UA\", \"UAA\", \"UNH\", \"USB\", \"V\", \"VRTX\",\n",
    "    \"WBA\", \"WDAY\", \"WFC\", \"WMT\", \"YUM\", \"ZBH\", \"ZM\"]\n",
    "\n",
    "# just to make sure that data is ordered correctly\n",
    "def order_data(df):\n",
    "    df = df.sort_values(by='date')\n",
    "    return df\n",
    "\n",
    "common_dates = None\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_data = pd.read_csv(f'{ticker}_1hr_historical_data_final.csv')\n",
    "    ticker_data['date'] = pd.to_datetime(ticker_data['date'], errors='coerce')\n",
    "\n",
    "    # Get ordered data\n",
    "    ticker_data_ordered = order_data(ticker_data)\n",
    "\n",
    "    # For ease of testing\n",
    "    ticker_data_truncated = ticker_data_ordered[(ticker_data_ordered['date'] >= ticker_data_ordered['date'].max() - timedelta(weeks=70))].copy()\n",
    "\n",
    "    # If common_dates is None, initialize it with the first ticker's dates\n",
    "    if common_dates is None:\n",
    "        common_dates = set(ticker_data_truncated['date'])\n",
    "    else:\n",
    "        # Keep only the dates that are common across tickers\n",
    "        common_dates &= set(ticker_data_truncated['date'])\n",
    "\n",
    "# Now, filter each ticker's data by the common dates\n",
    "ticker_arrays = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_data = pd.read_csv(f'{ticker}_1hr_historical_data_final.csv')\n",
    "    ticker_data['date'] = pd.to_datetime(ticker_data['date'], errors='coerce')\n",
    "\n",
    "    # Order data\n",
    "    ticker_data_ordered = order_data(ticker_data)\n",
    "\n",
    "    # For ease of testing\n",
    "    ticker_data_truncated = ticker_data_ordered[(ticker_data_ordered['date'] >= ticker_data_ordered['date'].max() - timedelta(weeks=30))].copy()\n",
    "\n",
    "    # Filter by common dates\n",
    "    ticker_data_filtered = ticker_data_truncated[ticker_data_truncated['date'].isin(common_dates)]\n",
    "\n",
    "    # Convert to numpy\n",
    "    ticker_array_half = ticker_data_filtered.to_numpy()\n",
    "\n",
    "    # Create empty dataframe for day and hour\n",
    "    ticker_data_filtered_date = pd.DataFrame()\n",
    "    ticker_data_filtered_date.loc[:, 'Day'] = ticker_data_filtered['date'].dt.dayofweek\n",
    "    ticker_data_filtered_date.loc[:, 'Hr'] = ticker_data_filtered['date'].dt.hour\n",
    "\n",
    "    ticker_array_datetime = ticker_data_filtered_date.to_numpy()\n",
    "\n",
    "    # Combine open, high, low, close, vol df with date hour df\n",
    "    total_ticker_array = np.concatenate((ticker_array_half[:, 1:-2], ticker_array_datetime), axis=1)\n",
    "\n",
    "    # Append to the list\n",
    "    ticker_arrays.append(total_ticker_array)\n",
    "# for each 2D array, the x 'rows' are my stocks\n",
    "# the y 'columns' are the time step\n",
    "# z is each calculate column/data column, i.e. open,hi,lo,close,vol, day,hr etc.\n",
    "len_initial_matrix = len(tickers) + 2\n",
    "\n",
    "ticker_matrix = np.stack(ticker_arrays, axis=0)\n",
    "print(ticker_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4760db8-fa72-4254-961a-17f1cf70d966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1013, 67)\n"
     ]
    }
   ],
   "source": [
    "# from github, just removes deprecated warnings etc.\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# massive function to calculate all technical indicators\n",
    "def add_indicators(matrix, k):\n",
    "    \n",
    "    rolling_window = 14\n",
    "    \n",
    "    open_col = pd.Series(matrix[k, :, 0])\n",
    "    high_col = pd.Series(matrix[k, :, 1])\n",
    "    low_col = pd.Series(matrix[k, :, 2])\n",
    "    close_col = pd.Series(matrix[k, :, 3])\n",
    "    volume_col = pd.Series(matrix[k, :, 4])\n",
    "\n",
    "    # Calculate indicators for the matrix\n",
    "    fisher = ta.fisher(high_col, low_col).iloc[:, 0].astype('float64')\n",
    "    dpo = ta.dpo(close_col)\n",
    "    corr = close_col.rolling(window=14).corr(close_col.shift(1))\n",
    "    adx = ta.adx(high_col, low_col, close_col)\n",
    "    rsi = ta.rsi(close_col)\n",
    "    uo = ta.uo(high_col, low_col, close_col)\n",
    "    willr = ta.willr(high_col, low_col, close_col)\n",
    "    kc_upper = ta.kc(high_col, low_col, close_col)\n",
    "    kama = ta.kama(close_col)\n",
    "    vtx = ta.vortex(high_col, low_col, close_col)\n",
    "    cmf = ta.cmf(high_col, low_col, close_col, volume_col)\n",
    "    kst = ta.kst(close_col)\n",
    "    eom = ta.eom(high_col, low_col, close_col, volume_col)\n",
    "    bop = ta.bop(open_col, high_col, low_col, close_col)\n",
    "    cci = ta.cci(high_col, low_col, close_col)\n",
    "    cmo = ta.cmo(close_col)\n",
    "    efi = (ta.efi(close_col, volume_col) - open_col) / open_col\n",
    "    eri = (ta.eri(high_col, low_col, close_col) - open_col) / open_col\n",
    "    ema = (ta.ema(close_col) - open_col) / open_col\n",
    "    hma = (ta.hma(close_col) - open_col) / open_col\n",
    "    linreg = (ta.linreg(close_col) - open_col) / open_col\n",
    "    slope = (ta.slope(close_col) - open_col) / open_col\n",
    "    median = (ta.median(close_col) - open_col) / open_col\n",
    "    macd = (ta.macd(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    mom = (ta.mom(close_col) - open_col) / open_col\n",
    "    obv = (ta.obv(close_col, volume_col) - open_col) / open_col\n",
    "    pvo = (ta.pvo(volume_col).iloc[:, 0] - open_col) / open_col\n",
    "    roc = (ta.roc(close_col) - open_col) / open_col\n",
    "    pvt = (ta.pvt(close_col, volume_col) - open_col) / open_col\n",
    "    sma = (ta.sma(close_col) - open_col) / open_col\n",
    "    stddev = (ta.stdev(close_col) - open_col) / open_col\n",
    "    supertrend = (ta.supertrend(high_col, low_col, close_col).iloc[:, 0] - open_col) / open_col\n",
    "    t3 = (ta.t3(close_col) - open_col) / open_col\n",
    "    trima = (ta.trima(close_col) - open_col) / open_col\n",
    "    true_range = (ta.true_range(high_col, low_col, close_col) - open_col) / open_col\n",
    "    wma = (ta.wma(close_col) - open_col) / open_col\n",
    "    tema = (ta.tema(close_col) - open_col) / open_col\n",
    "    nvi = (ta.nvi(close_col, volume_col) - open_col) / open_col\n",
    "    nvi = nvi.infer_objects()\n",
    "    pvi = (ta.pvi(close_col, volume_col) - open_col) / open_col\n",
    "    pvi = pvi.infer_objects()\n",
    "    chop = (ta.chop(high_col, low_col, close_col) - open_col) / open_col\n",
    "    atr = (ta.atr(high_col, low_col, close_col) - open_col) / open_col\n",
    "    ao = (ta.ao(high_col, low_col) - open_col) / open_col\n",
    "    dm = (ta.dm(high_col, low_col).iloc[:, 0] - open_col) / open_col\n",
    "    dema = (ta.dema(close_col) - open_col) / open_col\n",
    "    bias = (ta.bias(close_col) - open_col) / open_col\n",
    "    cfo = (ta.cfo(close_col) - open_col) / open_col\n",
    "    cti = (ta.cti(close_col) - open_col) / open_col\n",
    "    inertia = (ta.inertia(close_col) - open_col) / open_col\n",
    "    inertia = inertia.infer_objects()\n",
    "    ppo = (ta.ppo(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    trix = (ta.trix(close_col).iloc[:, 0] - open_col) / open_col\n",
    "    alma = (ta.alma(close_col) - open_col) / open_col\n",
    "    fwma = (ta.fwma(close_col) - open_col) / open_col\n",
    "    hilo = (ta.hilo(high_col, low_col, close_col).iloc[:, 0] - open_col) / open_col\n",
    "    hl2 = (ta.hl2(high_col, low_col) - open_col) / open_col\n",
    "    hwma = (ta.hwma(close_col) - open_col) / open_col\n",
    "    midpoint = (ta.midpoint(close_col) - open_col) / open_col\n",
    "    midprice = (ta.midprice(high_col, low_col) - open_col) / open_col\n",
    "    pwma = (ta.pwma(close_col) - open_col) / open_col\n",
    "    sinwma = (ta.sinwma(close_col) - open_col) / open_col\n",
    "    percent_return = ta.percent_return(close_col)\n",
    "    percent_return = percent_return.infer_objects()  # Add this only if it triggers the same warning   # Percent return doesn't need rolling mean\n",
    "    kurtosis = (ta.kurtosis(close_col) - open_col) / open_col\n",
    "    mad = (ta.mad(close_col) - open_col) / open_col\n",
    "    skew = (ta.skew(close_col) - open_col) / open_col\n",
    "    variance = (ta.variance(close_col) - open_col) / open_col\n",
    "\n",
    "    new_columns = [\n",
    "        fisher - fisher.rolling(rolling_window).mean(),\n",
    "        dpo - dpo.rolling(rolling_window).mean(),\n",
    "        corr - corr.rolling(rolling_window).mean(),\n",
    "        adx['ADX_14'] - adx['ADX_14'].rolling(rolling_window).mean(),\n",
    "        rsi - rsi.rolling(rolling_window).mean(),\n",
    "        uo - uo.rolling(rolling_window).mean(),\n",
    "        willr - willr.rolling(rolling_window).mean(),\n",
    "        kc_upper - kc_upper.rolling(rolling_window).mean(),\n",
    "        kama - kama.rolling(rolling_window).mean(),\n",
    "        vtx - vtx.rolling(rolling_window).mean(),\n",
    "        cmf - cmf.rolling(rolling_window).mean(),\n",
    "        kst - kst.rolling(rolling_window).mean(),\n",
    "        eom - eom.rolling(rolling_window).mean(),\n",
    "        bop - bop.rolling(rolling_window).mean(),\n",
    "        cci - cci.rolling(rolling_window).mean(),\n",
    "        cmo - cmo.rolling(rolling_window).mean(),\n",
    "        efi - efi.rolling(rolling_window).mean(),\n",
    "        ema - ema.rolling(rolling_window).mean(),\n",
    "        hma - hma.rolling(rolling_window).mean(),\n",
    "        linreg - linreg.rolling(rolling_window).mean(),\n",
    "        slope - slope.rolling(rolling_window).mean(),\n",
    "        median - median.rolling(rolling_window).mean(),\n",
    "        macd - macd.rolling(rolling_window).mean(),\n",
    "        mom - mom.rolling(rolling_window).mean(),\n",
    "        obv - obv.rolling(rolling_window).mean(),\n",
    "        pvo - pvo.rolling(rolling_window).mean(),\n",
    "        roc - roc.rolling(rolling_window).mean(),\n",
    "        pvt - pvt.rolling(rolling_window).mean(),\n",
    "        sma - sma.rolling(rolling_window).mean(),\n",
    "        stddev - stddev.rolling(rolling_window).mean(),\n",
    "        supertrend - supertrend.rolling(rolling_window).mean(),\n",
    "        t3 - t3.rolling(rolling_window).mean(),\n",
    "        trima - trima.rolling(rolling_window).mean(),\n",
    "        true_range - true_range.rolling(rolling_window).mean(),\n",
    "        wma - wma.rolling(rolling_window).mean(),\n",
    "        kurtosis - kurtosis.rolling(rolling_window).mean(),\n",
    "        mad - mad.rolling(rolling_window).mean(),\n",
    "        skew - skew.rolling(rolling_window).mean(),\n",
    "        variance - variance.rolling(rolling_window).mean(),\n",
    "        tema - tema.rolling(rolling_window).mean(),\n",
    "        nvi - nvi.rolling(rolling_window).mean(),\n",
    "        pvi - pvi.rolling(rolling_window).mean(),\n",
    "        chop - chop.rolling(rolling_window).mean(),\n",
    "        atr - atr.rolling(rolling_window).mean(),\n",
    "        ao - ao.rolling(rolling_window).mean(),\n",
    "        dm - dm.rolling(rolling_window).mean(),\n",
    "        dema - dema.rolling(rolling_window).mean(),\n",
    "        bias - bias.rolling(rolling_window).mean(),\n",
    "        cfo - cfo.rolling(rolling_window).mean(),\n",
    "        cti - cti.rolling(rolling_window).mean(),\n",
    "        inertia - inertia.rolling(rolling_window).mean(),\n",
    "        ppo - ppo.rolling(rolling_window).mean(),\n",
    "        trix - trix.rolling(rolling_window).mean(),\n",
    "        alma - alma.rolling(rolling_window).mean(),\n",
    "        fwma - fwma.rolling(rolling_window).mean(),\n",
    "        hilo - hilo.rolling(rolling_window).mean(),\n",
    "        hl2 - hl2.rolling(rolling_window).mean(),\n",
    "        hwma - hwma.rolling(rolling_window).mean(),\n",
    "        midpoint - midpoint.rolling(rolling_window).mean(),\n",
    "        midprice - midprice.rolling(rolling_window).mean(),\n",
    "        pwma - pwma.rolling(rolling_window).mean(),\n",
    "        sinwma - sinwma.rolling(rolling_window).mean(),\n",
    "        percent_return - percent_return.rolling(rolling_window).mean()  # No rolling mean needed\n",
    "    ]\n",
    "\n",
    "    # Stack the columns side by side and return\n",
    "    indicator_matrix = np.column_stack(new_columns)\n",
    "\n",
    "    return indicator_matrix\n",
    "\n",
    "indicator_arrays = []\n",
    "\n",
    "for r in range(ticker_matrix.shape[0]):\n",
    "    ind_per_stock = add_indicators(ticker_matrix, r)\n",
    "    indicator_arrays.append(ind_per_stock)\n",
    "    num_of_indicators = ind_per_stock.shape[0]\n",
    "\n",
    "#create new matrix for only indicators for each ticker\n",
    "indicator_matrix =  np.stack(indicator_arrays, axis = 0)\n",
    "print(indicator_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4091a32e-1328-4a00-beb3-06a460f4799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1013, 67)\n"
     ]
    }
   ],
   "source": [
    "num_stocks = len(tickers)\n",
    "\n",
    "#cros rank and scale rankings of indicators\n",
    "def cross_rank(matrix):\n",
    "    ranked_matrix = np.zeros(matrix.shape)\n",
    "\n",
    "    for j in range(matrix.shape[1]): \n",
    "        \n",
    "        for k in range(matrix.shape[2]):\n",
    "            \n",
    "            values_at_time_j = matrix[:, j, k]\n",
    "            \n",
    "            ranked_values = pd.Series(values_at_time_j).rank() / num_stocks\n",
    "\n",
    "            ranked_values = ranked_values.fillna(0)\n",
    "            \n",
    "            ranked_matrix[:, j, k] = ranked_values.to_numpy()\n",
    "\n",
    "    return ranked_matrix\n",
    "\n",
    "ranked_indicator_mat = cross_rank(indicator_matrix)\n",
    "print(ranked_indicator_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee02879-03ed-4cd3-b071-137a7c7116b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1013, 67)\n"
     ]
    }
   ],
   "source": [
    "#bin all ranked indicator values into quintiles\n",
    "def quantiler(matrix):\n",
    "    quantiled_matrix = np.zeros(matrix.shape)\n",
    "\n",
    "    for j in range(matrix.shape[1]): \n",
    "        \n",
    "        for k in range(matrix.shape[2]):\n",
    "\n",
    "            values_at_time_j = matrix[:, j, k]\n",
    "            values_series = pd.Series(values_at_time_j)\n",
    "\n",
    "            quantiled_vals = pd.cut(\n",
    "                values_series,\n",
    "                bins=[0, 1/5, 2/5, 3/5, 4/5, 1], \n",
    "                labels=[1, 2, 3, 4, 5], \n",
    "                include_lowest=True\n",
    "            ).astype(int)\n",
    "            \n",
    "            quantiled_matrix[:, j, k] = quantiled_vals.to_numpy()\n",
    "\n",
    "    return quantiled_matrix\n",
    "\n",
    "quantiled_indicator_mat = quantiler(ranked_indicator_mat)\n",
    "print(quantiled_indicator_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32c6970-5b55-410e-9b41-6fae5ff05c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1013, 74)\n"
     ]
    }
   ],
   "source": [
    "#combined quantiles values and initial price values/date values (required for later label calculations and such)\n",
    "quantiled_stocks_and_vals = np.concatenate((ticker_matrix ,quantiled_indicator_mat), axis = 2)\n",
    "print(quantiled_stocks_and_vals.shape)\n",
    "#columns on z axis 0-4 are my open,hi,lo,cl,vol, 5-6 are day, hr, rest are inds \n",
    "#cols 0-5 on x are my stocks\n",
    "#cols on y are timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "220b83bc-4847-47f2-ad12-873191aeb19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 50, 74)\n"
     ]
    }
   ],
   "source": [
    "# Apply initial filter to select only Mondays (day=0, hour=14) and Fridays (day=4, hour=20)\n",
    "filter = (\n",
    "    ((quantiled_stocks_and_vals[:, :, 5] == 0) & (quantiled_stocks_and_vals[:, :, 6] == 14)) |\n",
    "    ((quantiled_stocks_and_vals[:, :, 5] == 4) & (quantiled_stocks_and_vals[:, :, 6] == 20))\n",
    ")\n",
    "\n",
    "mondays_fridays_matrix = quantiled_stocks_and_vals[filter]\n",
    "#have to reshape arrays after \n",
    "mondays_fridays_matrix = mondays_fridays_matrix.reshape(quantiled_stocks_and_vals.shape[0], -1, quantiled_stocks_and_vals.shape[2])\n",
    "\n",
    "# Remove initial row if it starts with a Friday, or last row if it ends with a Monday\n",
    "if mondays_fridays_matrix[0, 0, 5] == 4:\n",
    "    cleaned_matrix = mondays_fridays_matrix[:, 1:, :]\n",
    "elif mondays_fridays_matrix[0, -1, 5] == 0:\n",
    "    cleaned_matrix = mondays_fridays_matrix[:, :-1, :]\n",
    "else:\n",
    "    cleaned_matrix = mondays_fridays_matrix\n",
    "\n",
    "# Filter out consecutive Fridays\n",
    "rows_to_keep_fri = [True]\n",
    "for i in range(1, cleaned_matrix.shape[1]):\n",
    "    if cleaned_matrix[0, i, 5] == 4 and cleaned_matrix[0, i - 1, 5] == 4:\n",
    "        rows_to_keep_fri.append(False)\n",
    "    else:\n",
    "        rows_to_keep_fri.append(True)\n",
    "\n",
    "filtered_matrix_initial = cleaned_matrix[:, rows_to_keep_fri, :]\n",
    "\n",
    "# Ensure rows_to_keep_mon matches the exact number of rows\n",
    "rows_to_keep_mon = [True]  # Start with the first row always being kept\n",
    "for i in range(1, filtered_matrix_initial.shape[1]):\n",
    "    if filtered_matrix_initial[0, i, 5] == 0 and filtered_matrix_initial[0, i - 1, 5] == 0:\n",
    "        rows_to_keep_mon.append(False)\n",
    "    else:\n",
    "        rows_to_keep_mon.append(True)\n",
    "\n",
    "# Ensure the boolean mask length matches the dimension of filtered_matrix_initial\n",
    "if len(rows_to_keep_mon) != filtered_matrix_initial.shape[1]:\n",
    "    rows_to_keep_mon = rows_to_keep_mon[:filtered_matrix_initial.shape[1]]\n",
    "\n",
    "# Apply the final filtering\n",
    "filtered_matrix_final = filtered_matrix_initial[:, rows_to_keep_mon, :]\n",
    "\n",
    "print(filtered_matrix_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1ec6096-5dd7-4be2-952c-ba320e93d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 50, 75)\n"
     ]
    }
   ],
   "source": [
    "def calc_FR(matrix):\n",
    "    FR_mats = []\n",
    "    for i in range(matrix.shape[0]):\n",
    "        forward_return = []\n",
    "        for j in range(int((matrix.shape[1])/2)):\n",
    "            forward_return.append(((matrix[i, 2*j+1, 0] - matrix[i, 2*j, 3])/matrix[i, 2*j, 3]) * 100)\n",
    "            forward_return.append(0)\n",
    "        \n",
    "        FR_mats.append(np.array(forward_return).reshape(-1, 1))\n",
    "    new_mat = np.stack(FR_mats)\n",
    "    \n",
    "    matrix_FR = np.concatenate((matrix, new_mat), axis = 2)\n",
    "\n",
    "    return matrix_FR\n",
    "\n",
    "matrix_with_FR = calc_FR(filtered_matrix_final)\n",
    "print(matrix_with_FR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab6d98af-e7c6-4c54-8003-78ad63aa4495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 25, 75)\n"
     ]
    }
   ],
   "source": [
    "def remove_fridays(matrix):\n",
    "    #5th column is day index\n",
    "    mask = matrix[:, :, 5] != 4\n",
    "    \n",
    "    cleaned_matrix = matrix[mask]\n",
    "    \n",
    "    cleaned_matrix = cleaned_matrix.reshape(matrix.shape[0], -1, matrix.shape[2])\n",
    "    \n",
    "    return cleaned_matrix\n",
    "\n",
    "monday_matrix = remove_fridays(matrix_with_FR)\n",
    "print(monday_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58616cf6-06a4-4178-b669-56ee5cc79a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 23, 76)\n"
     ]
    }
   ],
   "source": [
    "#labelling thresholds\n",
    "top_threshold = int(0.3 * num_stocks)\n",
    "bottom_threshold = int(0.7 * num_stocks)\n",
    "\n",
    "#ranking forward return, then labelling 1 or -1 or 0\n",
    "def rank_label_FR(matrix): \n",
    "    labeled_matrix = np.zeros((matrix.shape[0], matrix.shape[1], 1)) \n",
    "    for j in range(matrix.shape[1]): \n",
    "        values_at_time_j = matrix[:, j, -1]\n",
    "\n",
    "        ranked_values = pd.Series(values_at_time_j).rank()\n",
    "    \n",
    "        labeled_values = ranked_values.apply(\n",
    "            lambda x: 1 if x <= top_threshold else (-1 if x > bottom_threshold else 0))\n",
    "    \n",
    "        labeled_matrix[:, j, -1] = labeled_values.to_numpy()\n",
    "\n",
    "    return labeled_matrix\n",
    "\n",
    "#concat my monday matrix with my label columns, delete top two y (date) rows, this gets rid of first two mondays which will have nan\n",
    "#values from indicator calcs\n",
    "labeled_matrix = np.concatenate((monday_matrix, rank_label_FR(monday_matrix)), axis = 2)[:, 2:, :]\n",
    "\n",
    "print(labeled_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25666572-4ad0-45c8-875f-ac54e44cd031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 2.0 4.0 ... 2.0 4.112669388721219 -1.0]\n",
      " [3.0 1.0 4.0 ... 1.0 -5.537421977896116 1.0]\n",
      " [1.0 5.0 1.0 ... 5.0 5.8051258633483735 -1.0]\n",
      " ...\n",
      " [1.0 3.0 2.0 ... 5.0 -4.31405187959495 1.0]\n",
      " [5.0 4.0 5.0 ... 4.0 -1.7080291970802945 1.0]\n",
      " [5.0 3.0 2.0 ... 4.0 2.1973160300840506 -1.0]]\n"
     ]
    }
   ],
   "source": [
    "def filter_labels(matrix):\n",
    "    filtered_labeled_matrix = []\n",
    "    for i in range(matrix.shape[0]):\n",
    "        mask = matrix[i, :, -1] != 0\n",
    "        \n",
    "        filtered_matrix = matrix[i, mask, :]\n",
    "\n",
    "        filtered_labeled_matrix.append(filtered_matrix)\n",
    "\n",
    "    total_filtered_matrix = np.concatenate(filtered_labeled_matrix, axis = 0)\n",
    "    \n",
    "    return total_filtered_matrix\n",
    "\n",
    "# 7 onwars means that we only include quantile vals for each stock and fr return labels\n",
    "#unfortunately second to last row is raw fr vals, as such just need to remmber to ignore them later\n",
    "training_mat = filter_labels(labeled_matrix)[:, 7:]\n",
    "#result mat is 2D, no need for 3D as do not need to differentiate when training until doing cross market \n",
    "print(training_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd9859cc-8bd9-4f24-a68a-309a08ffd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Underperformer (-1)       0.63      0.68      0.65       424\n",
      "  Overperformer (1)       0.66      0.61      0.64       439\n",
      "\n",
      "           accuracy                           0.65       863\n",
      "          macro avg       0.65      0.65      0.65       863\n",
      "       weighted avg       0.65      0.65      0.65       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_ = training_mat[:, :-2]\n",
    "y = training_mat[:, -1]\n",
    "\n",
    "y = y.astype(int)\n",
    "X = X.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=80,\n",
    "    algorithm='SAMME',\n",
    "    learning_rate=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Underperformer (-1)', 'Overperformer (1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d686f-d8c0-4b90-90cf-06a5404a006b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
